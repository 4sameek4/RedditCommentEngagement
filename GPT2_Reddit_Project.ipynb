{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Imports\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "_o22TtV1evrw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load Dataset from KaggleHub\n",
        "path = kagglehub.dataset_download(\"smagnan/1-million-reddit-comments-from-40-subreddits\")\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(f\"{path}/kaggle_RC_2019-05.csv\", low_memory=False)"
      ],
      "metadata": {
        "id": "65vHvL27e16I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 10,000 comments for faster training\n",
        "df = df.sample(n=30000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Print dataset shape and head\n",
        "print(df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "To_NAVkKe4Fu",
        "outputId": "33c96f79-b558-4f57-9a0e-4c40140f7071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 4)\n",
            "        subreddit                                               body  \\\n",
            "0     apexlegends  How ironic that you're being indignant on the ...   \n",
            "1  ChapoTrapHouse  I started work in 99 when the boomers we're st...   \n",
            "2        Market76  Any combination of the following:\\n\\nAAE Pump ...   \n",
            "3       worldnews  Compare pharma's marketing budget to it's R&am...   \n",
            "4       worldnews                Wasn't it an illegitimate election?   \n",
            "\n",
            "   controversiality  score  \n",
            "0                 0      0  \n",
            "1                 0      2  \n",
            "2                 0      1  \n",
            "3                 0      1  \n",
            "4                 0      2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Convert score into class labels\n",
        "def convert_score(score):\n",
        "    if score < 1:\n",
        "        return 0  # Negative\n",
        "    elif score == 1:\n",
        "        return 1  # Neutral\n",
        "    else:\n",
        "        return 2  # Positive\n"
      ],
      "metadata": {
        "id": "QlGtc2GIfGIG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['score'].apply(convert_score)"
      ],
      "metadata": {
        "id": "fXg8KKLbfJkd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s4yxHCxuErZd"
      },
      "outputs": [],
      "source": [
        "# 4. Train-test split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['body'].tolist(),\n",
        "    df['label'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 5. Load GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Important for GPT-2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Define custom Dataset\n",
        "class RedditDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_len)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "metadata": {
        "id": "_Rtnrj_Se_ZK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Create dataset objects\n",
        "train_dataset = RedditDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = RedditDataset(val_texts, val_labels, tokenizer)\n"
      ],
      "metadata": {
        "id": "Vyy-ZfELeqs9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Load GPT-2 for Sequence Classification\n",
        "model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=3)\n",
        "model.config.pad_token_id = model.config.eos_token_id  # Important for GPT-2\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.train()  # Set model to training mode"
      ],
      "metadata": {
        "id": "X1-5Zwfdejws",
        "outputId": "c53bc5ea-6cc0-4bc1-91de-7362dc8d0d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2ForSequenceClassification(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 9. Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\"\n",
        "    # Removed evaluation_strategy and save_strategy for compatibility\n",
        ")"
      ],
      "metadata": {
        "id": "VcUuhEHPeJVX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "8g2Grj5MeJLY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 11. Train the model\n",
        "trainer.train()\n",
        "\n",
        "# 12. Evaluate the model\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "qQT0MFN-eU94",
        "outputId": "fc443fa3-efb9-458a-ac95-19cdcde03348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='184' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 184/4500 01:11 < 28:16, 2.54 it/s, Epoch 0.12/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NQHNjL7Htjn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict on validation set\n",
        "predictions = trainer.predict(val_dataset)\n",
        "\n",
        "# Extract logits and true labels\n",
        "logits = predictions.predictions\n",
        "y_pred = logits.argmax(axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n",
        "# # Print full classification report\n",
        "# print(\"\\nClassification Report:\\n\")\n",
        "# print(classification_report(y_true, y_pred, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ... (Your existing code to generate classification_report) ...\n",
        "\n",
        "# Get the classification report as a dictionary\n",
        "report_dict = classification_report(y_true, y_pred, target_names=[\"Negative\", \"Neutral\", \"Positive\"], output_dict=True)\n",
        "\n",
        "# Extract relevant metrics\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "classes = ['Negative', 'Neutral', 'Positive']\n",
        "data = np.array([[report_dict[c][m] for m in metrics] for c in classes])\n",
        "\n",
        "# Create the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "width = 0.2  # Width of each bar\n",
        "x = np.arange(len(classes))\n",
        "\n",
        "# Plot bars for each metric\n",
        "rects1 = ax.bar(x - width, data[:, 0], width, label='Precision')\n",
        "rects2 = ax.bar(x, data[:, 1], width, label='Recall')\n",
        "rects3 = ax.bar(x + width, data[:, 2], width, label='F1-score')\n",
        "\n",
        "# Set labels, title, and legend\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Classification Report')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(classes)\n",
        "ax.legend()\n",
        "\n",
        "# Add value labels on top of bars\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1Y0IBJ-UD8x"
      },
      "outputs": [],
      "source": [
        "# Function to predict sentiment from user input\n",
        "def predict_user_input(text, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    label_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "    return label_mapping[pred]\n",
        "\n",
        "# Take input from user\n",
        "user_text = input(\"\\nEnter a comment for sentiment prediction: \")\n",
        "\n",
        "#  Predict label\n",
        "predicted_label = predict_user_input(user_text, model, tokenizer, device)\n",
        "\n",
        "# Print output\n",
        "print(f\"\\nPredicted Sentiment: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSp8BNzTVn7x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}